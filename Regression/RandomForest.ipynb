{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports ##\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:  \n",
    "n_estimators: (int) The number of trees in the forest.  \n",
    "max_features: (int) The number of features to consider when looking for the best split   \n",
    "max_depth: (int) The maximum depth of the tree  \n",
    "min_samples_split: (int) The minimum number of samples required to split an internal node  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=None, max_features=None, max_depth=None, min_samples_split=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "\n",
    "    def entropy(self, p):\n",
    "        if p == 0:\n",
    "            return 0\n",
    "        elif p == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return - (p * np.log2(p) + (1 - p) * np.log2(1-p))\n",
    "    \n",
    "    def information_gain(self, left_child, right_child):\n",
    "        parent = left_child + right_child\n",
    "        p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
    "        p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
    "        p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
    "        IG_p = self.entropy(p_parent)\n",
    "        IG_l = self.entropy(p_left)\n",
    "        IG_r = self.entropy(p_right)\n",
    "        return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r\n",
    "\n",
    "    \n",
    "    def draw_bootstrap(self, X_train, y_train):\n",
    "        bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
    "        oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
    "        X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
    "        y_bootstrap = y_train[bootstrap_indices]\n",
    "        X_oob = X_train.iloc[oob_indices].values\n",
    "        y_oob = y_train[oob_indices]\n",
    "        return X_bootstrap, y_bootstrap, X_oob, y_oob\n",
    "\n",
    "    def oob_score(self, tree, X_test, y_test):\n",
    "        mis_label = 0\n",
    "        for i in range(len(X_test)):\n",
    "            pred = self.predict_tree(tree, X_test[i])\n",
    "            if pred != y_test[i]:\n",
    "                mis_label += 1\n",
    "        return mis_label / len(X_test)\n",
    "    \n",
    "    def find_split_point(self, X_bootstrap, y_bootstrap, max_features):\n",
    "        feature_ls = list()\n",
    "        num_features = len(X_bootstrap[0])\n",
    "        \n",
    "        while len(feature_ls) <= max_features:\n",
    "            feature_idx = random.sample(range(num_features), 1)\n",
    "            if feature_idx not in feature_ls:\n",
    "                feature_ls.extend(feature_idx)\n",
    "        \n",
    "        best_info_gain = -999\n",
    "        node = None\n",
    "        for feature_idx in feature_ls:\n",
    "            for split_point in X_bootstrap[:,feature_idx]:\n",
    "                left_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "                right_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "                \n",
    "                # split children for continuous variables\n",
    "                if type(split_point) in [int, float]:\n",
    "                    split_point = float(split_point)\n",
    "                    for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                        #print(value, split_point)\n",
    "                        try:\n",
    "                            if value <= split_point:\n",
    "                                left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                                left_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                            else:\n",
    "                                right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                                right_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                        except(TypeError):\n",
    "                            print(\"Error occurred with split_point type:\", split_point, type(split_point))\n",
    "                            print(\"Error occurred with value type:\", value, type(value))\n",
    "                            print(\"Error occurred in column:\", X_bootstrap[:, feature_idx])\n",
    "                            raise  # Re-raise the exception to halt the program\n",
    "                # split children for categoric variables\n",
    "                else:\n",
    "                    for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                        if value == split_point:\n",
    "                            left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                            left_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                        else:\n",
    "                            right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                            right_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                \n",
    "                split_info_gain = self.information_gain(left_child['y_bootstrap'], right_child['y_bootstrap'])\n",
    "                if split_info_gain > best_info_gain:\n",
    "                    best_info_gain = split_info_gain\n",
    "                    left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
    "                    right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
    "                    node = {'information_gain': split_info_gain, \n",
    "                            'left_child': left_child, \n",
    "                            'right_child': right_child, \n",
    "                            'split_point': split_point,\n",
    "                            'feature_idx': feature_idx}\n",
    "                    \n",
    "        \n",
    "        return node\n",
    "        \n",
    "    def terminal_node(self, node):\n",
    "        y_bootstrap = node['y_bootstrap']\n",
    "        pred = max(y_bootstrap, key = y_bootstrap.count)\n",
    "        return pred\n",
    "\n",
    "    def split_node(self, node, max_features, min_samples_split, max_depth, depth):\n",
    "        left_child = node['left_child']\n",
    "        right_child = node['right_child']    \n",
    "\n",
    "        del(node['left_child'])\n",
    "        del(node['right_child'])\n",
    "        \n",
    "        if len(left_child['y_bootstrap']) == 0 or len(right_child['y_bootstrap']) == 0:\n",
    "            empty_child = {'y_bootstrap': left_child['y_bootstrap'] + right_child['y_bootstrap']}\n",
    "            node['left_split'] = self.terminal_node(empty_child)\n",
    "            node['right_split'] = self.terminal_node(empty_child)\n",
    "            return\n",
    "        \n",
    "        if depth >= max_depth:\n",
    "            node['left_split'] = self.terminal_node(left_child)\n",
    "            node['right_split'] = self.terminal_node(right_child)\n",
    "            return node\n",
    "        \n",
    "        if len(left_child['X_bootstrap']) <= min_samples_split:\n",
    "            node['left_split'] = node['right_split'] = self.terminal_node(left_child)\n",
    "        else:\n",
    "            node['left_split'] = self.find_split_point(left_child['X_bootstrap'], left_child['y_bootstrap'], max_features)\n",
    "            self.split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
    "        if len(right_child['X_bootstrap']) <= min_samples_split:\n",
    "            node['right_split'] = node['left_split'] = self.terminal_node(right_child)\n",
    "        else:\n",
    "            node['right_split'] = self.find_split_point(right_child['X_bootstrap'], right_child['y_bootstrap'], max_features)\n",
    "            self.split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)\n",
    "\n",
    "\n",
    "    def build_tree(self, X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):\n",
    "        root_node = self.find_split_point(X_bootstrap, y_bootstrap, max_features)\n",
    "        self.split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
    "        return root_node\n",
    "\n",
    "    def fit(self, X_train, y_train, n_estimators, max_features, max_depth, min_samples_split):\n",
    "        tree_ls = list()\n",
    "        oob_ls = list()\n",
    "        for i in range(n_estimators):\n",
    "            X_bootstrap, y_bootstrap, X_oob, y_oob = self.draw_bootstrap(X_train, y_train)\n",
    "            tree = self.build_tree(X_bootstrap, y_bootstrap, max_features, max_depth, min_samples_split)\n",
    "            tree_ls.append(tree)\n",
    "            oob_error = self.oob_score(tree, X_oob, y_oob)\n",
    "            oob_ls.append(oob_error)\n",
    "        print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
    "        return tree_ls \n",
    "\n",
    "    def predict_tree(self, tree, X_test):\n",
    "        feature_idx = tree['feature_idx']\n",
    "        \n",
    "        if X_test[feature_idx] <= tree['split_point']:\n",
    "            if type(tree['left_split']) == dict:\n",
    "                return self.predict_tree(tree['left_split'], X_test)\n",
    "            else:\n",
    "                value = tree['left_split']\n",
    "                return value\n",
    "        else:\n",
    "            if type(tree['right_split']) == dict:\n",
    "                return self.predict_tree(tree['right_split'], X_test)\n",
    "            else:\n",
    "                return tree['right_split']       \n",
    "\n",
    "    def predict_rf(self, tree_ls, X_test):\n",
    "        pred_ls = list()\n",
    "        for i in range(len(X_test)):\n",
    "            ensemble_preds = [self.predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
    "            final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
    "            pred_ls.append(final_pred)\n",
    "        return np.array(pred_ls)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   \n",
       "0            1         0       3  \\\n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp   \n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r'titatnic_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests are not robust enough to handle missing values, therefore it is necessary to handle null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB estimate: 0.31\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r'titatnic_train.csv')\n",
    "df.head()\n",
    "df.drop(columns=\"Cabin\",inplace=True)\n",
    "df.drop(columns=\"Embarked\",inplace=True)\n",
    "features = ['Pclass','Sex','Age','SibSp','Parch', 'Fare']\n",
    "nb_train = int(np.floor(0.9 * len(df)))\n",
    "df = df.sample(frac=1, random_state=217)\n",
    "X_train = df[features][:nb_train]\n",
    "y_train = df['Survived'][:nb_train].values\n",
    "X_test = df[features][nb_train:]\n",
    "y_test = df['Survived'][nb_train:].values\n",
    "df.loc[df['Age'].isnull(),'Age'] = np.round(df['Age'].mean())\n",
    "# Replace null values with mean of their corresponding attribute (only for numerical columns)\n",
    "for column in df.columns:\n",
    "    if df[column].dtype in ['int64', 'float64']:\n",
    "        mean_value = df[column].mean()\n",
    "        df[column].fillna(mean_value, inplace=True)\n",
    "\n",
    "n_estimators = 100\n",
    "max_features = 3\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "\n",
    "rf = RandomForest(n_estimators, max_features, max_depth, min_samples_split)\n",
    "model = rf.fit(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict_rf(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.589\n"
     ]
    }
   ],
   "source": [
    "acc = sum(preds == y_test) / len(y_test)\n",
    "print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.856\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('titatnic_train.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "df.drop(columns=[\"Cabin\", \"Embarked\"], inplace=True)\n",
    "df.loc[df['Age'].isnull(), 'Age'] = np.round(df['Age'].mean())\n",
    "for column in df.columns:\n",
    "    if df[column].dtype in ['int64', 'float64']:\n",
    "        mean_value = df[column].mean()\n",
    "        df[column].fillna(mean_value, inplace=True)\n",
    "\n",
    "# Convert categorical variables to one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Sex'])\n",
    "\n",
    "# Define features and split data into train and test sets\n",
    "features = ['Pclass', 'Sex_female', 'Sex_male', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "nb_train = int(np.floor(0.9 * len(df)))\n",
    "df = df.sample(frac=1, random_state=217)\n",
    "X_train = df[features][:nb_train]\n",
    "y_train = df['Survived'][:nb_train]\n",
    "X_test = df[features][nb_train:]\n",
    "y_test = df['Survived'][nb_train:]\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "n_estimators = 100\n",
    "max_features = 3\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   max_features=max_features,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Testing accuracy: {}\".format(np.round(acc, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our random forest classifier is just a learning project where in we are trying to mimick the functionalities of scikit learn's random forest classifier you can see a difference in accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
